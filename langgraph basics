import os
from typing import TypedDict, List
from langgraph.graph import StateGraph, END
from langchain.prompts import PromptTemplate
from langchain_core.runnables.graph import MermaidDrawMethod
from IPython.display import display, Image
from dotenv import load_dotenv

# BlueConic GenAI imports
from blueconic import Client
from blueconic.domain.genai import Message

# Load environment variables
load_dotenv()

# Initialize BlueConic GenAI client
bc = Client()

# Define the state structure
class State(TypedDict):
    text: str
    classification: str
    entities: List[str]
    summary: str

# Helper function to get BlueConic chat completion
def blueconic_completion(prompt: str) -> str:
    messages = [Message(role=Message.Role.USER, content=prompt)]
    response = bc.get_chat_completion(messages)
    return response.choices[0].message.content.strip()

# Classification Node
def classification_node(state: State):
    ''' Classify the text into one of the categories: News, Blog, Research, or Other '''
    prompt_template = PromptTemplate(
        input_variables=["text"],
        template="Classify the following text into one of the categories: News, Blog, Research, or Other.\n\nText:{text}\n\nCategory:"
    )
    prompt = prompt_template.format(text=state["text"])
    classification = blueconic_completion(prompt)
    return {"classification": classification}

# Entity Extraction Node
def entity_extraction_node(state: State):
    ''' Extract all the entities (Person, Organization, Location) from the text '''
    prompt_template = PromptTemplate(
        input_variables=["text"],
        template="Extract all the entities (Person, Organization, Location) from the following text. Provide the result as a comma-separated list.\n\nText:{text}\n\nEntities:"
    )
    prompt = prompt_template.format(text=state["text"])
    entities = blueconic_completion(prompt).split(", ")
    return {"entities": entities}

# Summarization Node
def summarization_node(state: State):
    ''' Summarize the text in one short sentence '''
    prompt_template = PromptTemplate(
        input_variables=["text"],
        template="Summarize the following text in one short sentence.\n\nText:{text}\n\nSummary:"
    )
    prompt = prompt_template.format(text=state["text"])
    summary = blueconic_completion(prompt)
    return {"summary": summary}

# Define the workflow graph
workflow = StateGraph(State)

# Add nodes
workflow.add_node("classification_node", classification_node)
workflow.add_node("entity_extraction", entity_extraction_node)
workflow.add_node("summarization", summarization_node)

# Add transitions
workflow.set_entry_point("classification_node")
workflow.add_edge("classification_node", "entity_extraction")
workflow.add_edge("entity_extraction", "summarization")
workflow.add_edge("summarization", END)

# Compile graph
app = workflow.compile()

# Display Mermaid diagram
display(
    Image(
        app.get_graph().draw_mermaid_png(
            draw_method=MermaidDrawMethod.API,
        )
    )
)

# Example input text
sample_text = """
OpenAI has announced the GPT-4 model, which is a large multimodal model that exhibits human-level performance on various professional benchmarks. It is developed to improve the alignment and safety of AI systems.
Additionally, the model is designed to be more efficient and scalable than its predecessor, GPT-3. The GPT-4 model is expected to be released in the coming months and will be available to the public for research and development purposes.
"""

# Invoke the graph
state_input = {"text": sample_text}
result = app.invoke(state_input)

# Output results
print("Classification:", result["classification"])
print("\nEntities:", result["entities"])
print("\nSummary:", result["summary"])
